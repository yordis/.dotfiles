name: ubi

volumes:
  postgresql-data:
    driver: local
  minio-data:
    driver: local
  nats-data:
    driver: local
  redis-data:
    driver: local
  eventstore-data:
    driver: local
  cockroach-data:
    driver: local
  opensearch-data:
    driver: local
  rabbitmq-data:
    driver: local
  browserless-data:
    driver: local
  mysql-data:
    driver: local
  open-webui:
    driver: local
  maybe-finance:
    driver: local

services:
  maybe-finance:
    container_name: maybe-finance
    profiles:
      - maybe-finance
    image: ghcr.io/maybe-finance/maybe:latest
    volumes:
      - maybe-finance:/rails/storage
    restart: unless-stopped
    environment:
      APP_DOMAIN: maybe-finance.ubi.orb.local
      REQUIRE_INVITE_CODE: false
      SELF_HOSTING_ENABLED: true
      DB_HOST: postgresql
      RAILS_FORCE_SSL: false
      RAILS_ASSUME_SSL: false
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      GOOD_JOB_EXECUTION_MODE: async
      SMTP_ADDRESS: mailhog
      SMTP_PORT: 1025
      HOSTING_PLATFORM: localhost
      SECRET_KEY_BASE: 88efe1b90eb800386b3e03e032ffa76d5fc2ec084770d699678d27f94a6bd9bd27ad51dad7781471d42825ca4b1ceceae7ffdb14f60737d8d1219a73af53f8f0
      GITHUB_REPO_OWNER: maybe-finance
      GITHUB_REPO_NAME: maybe
      GITHUB_REPO_BRANCH: main
    depends_on:
      postgresql:
        condition: service_healthy

  open-webui:
    profiles:
      - ollama
    container_name: open-webui
    image: ghcr.io/open-webui/open-webui:main
    restart: unless-stopped
    volumes:
      - open-webui:/app/backend/data
    environment:
      OLLAMA_BASE_URL: http://host.docker.internal:11434

  watchtower:
    container_name: watchtower
    image: containrrr/watchtower:latest
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  mysql:
    profiles:
      - mysql
    container_name: mysql
    image: mysql:latest
    restart: unless-stopped
    volumes:
      - mysql-data:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_ALLOW_EMPTY_PASSWORD: "yes"
      MYSQL_USER: admin
      MYSQL_PASSWORD: adminpass

  rabbitmq:
    profiles:
      - rabbitmq
    container_name: rabbitmq
    image: rabbitmq:management
    healthcheck:
      test: ["CMD", "rabbitmqctl", "status"]
      timeout: 20s
      retries: 10
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq

  schema-registry:
    container_name: schema-registry
    profiles:
      - kafka
    image: confluentinc/cp-schema-registry:latest
    depends_on:
      - zookeeper
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:9092

  redpanda-console:
    container_name: redpanda-console
    profiles:
      - kafka
    image: redpandadata/console:latest
    entrypoint: /bin/sh
    command: -c "echo \"$$CONSOLE_CONFIG_FILE\" > /tmp/config.yml; /app/console"
    depends_on:
      - zookeeper
      - kafka
      - schema-registry
    labels:
      - dev.orbstack.https-port=8081
    environment:
      CONFIG_FILEPATH: /tmp/config.yml
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["kafka:9092"]
          schemaRegistry:
            enabled: true
            urls: ["http://schema-registry:8081"]

  zookeeper:
    container_name: zookeeper
    profiles:
      - kafka
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ALLOW_ANONYMOUS_LOGIN: yes

  kafka:
    container_name: kafka
    profiles:
      - kafka
    image: confluentinc/cp-kafka:latest
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true

  opensearch-dashboards:
    container_name: opensearch-dashboards
    profiles:
      - opensearch
    image: opensearchproject/opensearch-dashboards:latest
    environment:
      OPENSEARCH_HOSTS: '["http://opensearch:9200"]'

  opensearch:
    container_name: opensearch
    profiles:
      - opensearch
      - temporal
    image: opensearchproject/opensearch:latest
    restart: unless-stopped
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    environment:
      - discovery.type=single-node
      - plugins.security.disabled=true
      - OPENSEARCH_JAVA_OPTS=-Xms256m -Xmx256m
      - cluster.routing.allocation.disk.threshold_enabled=true
      - cluster.routing.allocation.disk.watermark.low=512mb
      - cluster.routing.allocation.disk.watermark.high=256mb
      - cluster.routing.allocation.disk.watermark.flood_stage=128mb
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=1PasswordAsdf!234
    volumes:
      - opensearch-data:/usr/share/opensearch/data

  cockroach:
    container_name: cockroach
    profiles:
      - cockroach
    restart: "always"
    image: "cockroachdb/cockroach:latest"
    command: "start-single-node --insecure"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health?ready=1"]
      interval: "10s"
      timeout: "30s"
      retries: 5
    volumes:
      - cockroach-data:/cockroach/cockroach-data

  zitadel:
    container_name: zitadel
    restart: "always"
    image: "ghcr.io/zitadel/zitadel:latest"
    command: 'start-from-init --masterkey "JuYLmMDXBljOuUghsNgnoB3AaEEFGOLY" --tlsMode disabled'
    environment:
      - ZITADEL_LOG_LEVEL=debug
      - ZITADEL_EXTERNALSECURE=false
      - ZITADEL_EXTERNALPORT=80
      - ZITADEL_EXTERNALDOMAIN=zitadel.ubi.orb.local
      - ZITADEL_DATABASE_POSTGRES_HOST=postgresql
      - ZITADEL_DATABASE_POSTGRES_PORT=5432
      - ZITADEL_DATABASE_POSTGRES_DATABASE=zitadel
      - ZITADEL_DATABASE_POSTGRES_USER_USERNAME=postgres
      - ZITADEL_DATABASE_POSTGRES_USER_PASSWORD=postgres
      - ZITADEL_DATABASE_POSTGRES_USER_SSL_MODE=disable
      - ZITADEL_DATABASE_POSTGRES_ADMIN_USERNAME=postgres
      - ZITADEL_DATABASE_POSTGRES_ADMIN_PASSWORD=postgres
      - ZITADEL_DATABASE_POSTGRES_ADMIN_SSL_MODE=disable
      - ZITADEL_FIRSTINSTANCE_ORG_HUMAN_USERNAME=root@zitadel.ubi.orb.local
      - ZITADEL_FIRSTINSTANCE_ORG_HUMAN_PASSWORD=Password1!
      - ZITADEL_FIRSTINSTANCE_ORG_HUMAN_PASSWORDCHANGEREQUIRED=false
      - ZITADEL_DEFAULTINSTANCE_SMTPCONFIGURATION_FROM=yordis.prieto@gmail.com
      - ZITADEL_DEFAULTINSTANCE_SMTPCONFIGURATION_SMTP_HOST=mailhog:1025
    depends_on:
      - postgresql

  browserless:
    container_name: browserless
    profiles:
      - browserless
    image: browserless/chrome:latest
    ports:
      - "3005:3000"
    volumes:
      - browserless-data:/data
    environment:
      WORKSPACE_DIR: /data/workspace
      DEBUG: browserless:*
      MAX_CONCURRENT_SESSIONS: 10
      CONNECTION_TIMEOUT: 60000
      MAX_QUEUE_LENGTH: 20
      PREBOOT_CHROME: true
      DEMO_MODE: false
      HOST: 0.0.0.0
      ENABLE_DEBUGGER: false
      PORT: 3000
      WORKSPACE_DELETE_EXPIRED: true

  nats:
    container_name: nats
    image: nats:latest
    ports:
      - "8222:8222"
      - "4222:4222"
      - "6222:6222"
      - "8874:8874"
    command: >-
      --http_port 8222
      --port 4222
      --jetstream
      --store_dir /data
      --config /nats-server.conf
    volumes:
      - nats-data:/data
      - ./services/nats/nats-server.conf:/nats-server.conf

  minio:
    container_name: minio
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
    environment:
      MINIO_ROOT_USER: AKIAIOSFODNN7EXAMPLE
      MINIO_ROOT_PASSWORD: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY

  mailhog:
    container_name: mailhog
    image: mailhog/mailhog:latest
    restart: unless-stopped
    ports:
      - "1026:1025"
      - "8026:8025"

  eventstore:
    container_name: eventstore
    image: eventstore/eventstore:latest
    restart: unless-stopped
    labels:
      - dev.orbstack.http-port=2113
    ports:
      - "2113:2113"
    volumes:
      - eventstore-data:/var/lib/eventstore
    environment:
      EVENTSTORE_CLUSTER_SIZE: 1
      EVENTSTORE_RUN_PROJECTIONS: All
      EVENTSTORE_START_STANDARD_PROJECTIONS: true
      EVENTSTORE_HTTP_PORT: 2113
      EVENTSTORE_INSECURE: true
      EVENTSTORE_ENABLE_ATOM_PUB_OVER_HTTP: true

  postgresql:
    container_name: postgresql
    command: postgres -c shared_preload_libraries=pg_stat_statements -c pg_stat_statements.track=all -c max_connections=200 -c pg_stat_statements.max=10000 -c track_activity_query_size=2048 -c wal_level=logical
    build:
      context: ./images/postgres
      dockerfile: Dockerfile
    restart: unless-stopped
    ports:
      - "5432:5432"
    volumes:
      - postgresql-data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: "10s"
      timeout: "30s"
      retries: 5

  redis:
    container_name: redis
    image: redis/redis-stack:latest
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data

  temporal:
    container_name: temporal
    profiles:
      - temporal
    image: temporalio/auto-setup:latest
    labels:
      kompose.volume.type: configMap
    ports:
      - "7233:7233"
    depends_on:
      - postgresql
      - opensearch
    volumes:
      - ./services/temporal/dynamicconfig:/etc/temporal/config/dynamicconfig
    environment:
      DB: postgres12
      DB_PORT: 5432
      POSTGRES_USER: postgres
      POSTGRES_PWD: postgres
      POSTGRES_SEEDS: postgresql
      DYNAMIC_CONFIG_FILE_PATH: /etc/temporal/config/dynamicconfig/development-sql.yaml
      ENABLE_ES: true
      ES_SEEDS: opensearch
      ES_VERSION: v7

  temporal-admin-tools:
    container_name: temporal-admin-tools
    profiles:
      - temporal
    image: temporalio/admin-tools:latest
    stdin_open: true
    tty: true
    depends_on:
      - temporal
    environment:
      TEMPORAL_ADDRESS: temporal:7233
      TEMPORAL_CLI_ADDRESS: temporal:7233

  temporal-ui:
    container_name: temporal-ui
    profiles:
      - temporal
    image: temporalio/ui:latest
    depends_on:
      - temporal
    environment:
      TEMPORAL_ADDRESS: temporal:7233
      TEMPORAL_CORS_ORIGINS: http://temporal-ui.ubi.orb.local
      TEMPORAL_CSRF_COOKIE_INSECURE: true

  spicedb:
    container_name: spicedb
    image: authzed/spicedb:latest
    command: serve
    profiles:
      - spicedb
    restart: unless-stopped
    ports:
      - "8880:8080"
      - "9890:9090"
      - "50051:50051"
    depends_on:
      - spicedb-migrate
      - postgresql
    environment:
      SPICEDB_GRPC_PRESHARED_KEY: foobar
      SPICEDB_DATASTORE_ENGINE: postgres
      SPICEDB_DATASTORE_CONN_URI: postgres://postgres:postgres@postgresql:5432/spicedb?sslmode=disable

  spicedb-migrate:
    container_name: spicedb-migrate
    profiles:
      - spicedb
    image: authzed/spicedb:latest
    command: migrate head
    restart: on-failure
    depends_on:
      - postgresql
    environment:
      SPICEDB_DATASTORE_ENGINE: postgres
      SPICEDB_DATASTORE_CONN_URI: postgres://postgres:postgres@postgresql:5432/spicedb

  mongodb:
    container_name: mongodb
    profiles:
      - mongodb
    image: mongo:latest
    restart: unless-stopped
    ports:
      - "27017:27017"

  centrifugo:
    container_name: centrifugo
    profiles:
      - centrifugo
    image: centrifugo/centrifugo:latest
    volumes:
      - ./services/centrifugo/config.json:/centrifugo/config.json
    command: centrifugo -c config.json
    labels:
      - dev.orbstack.https-port=8000
    ulimits:
      nofile:
        soft: 65535
        hard: 65535
